class auto_encoder(nn.Module):
    def __init__(self):
        super(auto_encoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(900, reduction_to_size),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(reduction_to_size, 900),
            nn.ReLU()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

    def encode(self, x):
        x = self.encoder(x)
        return x



def dimension_reduction(map_lst, run_id):
    num_epochs = 2500
    batch_size = 128
    learning_rate = 0.005

    model = auto_encoder().cuda()
    criterion = nn.MSELoss()
    optimizer = torch.optim.SGD(
        model.parameters(), lr=learning_rate, momentum=0.9)

    my_x = []  # a list of numpy arrays
    for formula_vector in map_lst.values():
        data = torch.from_numpy(formula_vector)
        data = data.float()
        my_x.append(data)

    tensor_x = torch.stack([torch.Tensor(i) for i in my_x])  # transform to torch tensors
    my_dataset = utils.TensorDataset(tensor_x)  # create your dataset

    validation_split = .15
    shuffle_dataset = True
    random_seed = 42